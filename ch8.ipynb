{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:29:53,075 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ImageID', 'Source', 'LabelName', 'Confidence', 'XMin', 'XMax', 'YMin',\n",
       "       'YMax', 'IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction',\n",
       "       'IsInside', 'XClick1X', 'XClick2X', 'XClick3X', 'XClick4X', 'XClick1Y',\n",
       "       'XClick2Y', 'XClick3Y', 'XClick4Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda,optim\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,models,datasets\n",
    "from torchvision.ops import nms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd,numpy as np\n",
    "import torchsummary\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from pandas import DataFrame as df\n",
    "import glob\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.FileHandler('app.log'), logging.StreamHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "DS_FOLDER = './data/open-images-bus-trucks/open-images-bus-trucks'\n",
    "IMAGE_ROOT = DS_FOLDER + '/images'\n",
    "df = pd.read_csv(DS_FOLDER+'/df.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2targets = {l: t+1 for t,l in enumerate(df['LabelName'].unique())}\n",
    "label2targets['background'] = 0\n",
    "target2labels = {i:t for t,i in label2targets.items()}\n",
    "background_class = label2targets['background']\n",
    "num_classes = len(label2targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img):\n",
    "    img = torch.tensor(img).permute(2,0,1)\n",
    "    return img.to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenDataset(Dataset):\n",
    "    def __init__(self,df,images_path=IMAGE_ROOT):\n",
    "        self.images_path = images_path\n",
    "        self.files = glob.glob(self.images_path,'/*')\n",
    "        self.df = df\n",
    "        self.image_info = df['ImageID'].unique()\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_info.iloc[index]\n",
    "        img_path = list(filter(lambda path : path.find(image_id)!=-1,self.files))[0]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = np.array(img.resize((self.w,self.h),resample = Image.BITLINEAR)/255)\n",
    "        data = df[df['ImageID'] == image_id]\n",
    "        labels = data['LabelName']\n",
    "        data = data[['XMin','YMin','XMax','YMax']].values()\n",
    "        data[:,[0,2]] *= self.w\n",
    "        data[:,[1,3]] *= self.h\n",
    "\n",
    "        boxes = data.astype(np.uint32).tolist()\n",
    "        target = {}\n",
    "        target['boxes'] = torch.Tensor(boxes).float()\n",
    "        target['label'] = torch.Tensor([label2targets[i] for i in labels]).long()\n",
    "        img = process_img(img)\n",
    "        return img,target\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        return tuple(*zip(batch))\n",
    "    def __len__(self):\n",
    "        return len(self.image_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
